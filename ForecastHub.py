#!/usr/bin/env python
# coding: utf-8
"""
FORECASTHUB PRO - Enterprise Sales Forecasting Suite
====================================================
Professional-grade on-premise forecasting with predictive analytics
All data remains 100% local and secure
"""

# ============================================
# CORE IMPORTS
# ============================================
import os
import sys
import traceback
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import warnings
warnings.filterwarnings('ignore')

# ============================================
# PATH SETUP - CRITICAL FOR PORTABILITY
# ============================================
def get_script_directory():
    """Get the directory where this script is located, works in all scenarios."""
    if getattr(sys, 'frozen', False):
        # Running as compiled executable (PyInstaller)
        return Path(sys.executable).parent
    else:
        # Running as normal Python script
        return Path(__file__).parent.absolute()

SCRIPT_DIR = get_script_directory()
print(f"ðŸ“‚ ForecastHub Pro working from: {SCRIPT_DIR}")

# Add our directory to Python path
sys.path.insert(0, str(SCRIPT_DIR))

# ============================================
# CONFIGURATION LOADER
# ============================================
def load_config():
    """Load configuration from config.json in the same directory."""
    config_path = SCRIPT_DIR / "config.json"
    
    if not config_path.exists():
        # Create default config
        default_config = {
            "forecast_horizon": 12,
            "confidence_level": 0.95,
            "min_data_months": 6,
            "default_output_dir": str(SCRIPT_DIR / "forecast_reports"),
            "generate_csv": True,
            "generate_excel": True,
            "generate_pdf": True,
            "generate_charts": True,
            "theme_color": "#2C3E50",
            "risk_thresholds": {
                "high_risk": 40,
                "medium_risk": 60,
                "low_risk": 80
            },
            "growth_thresholds": {
                "high_growth": 20,
                "moderate_growth": 10,
                "decline": -5
            }
        }
        
        with open(config_path, "w") as f:
            json.dump(default_config, f, indent=2)
        print("âœ… Created default config.json")
        return default_config
    
    with open(config_path, "r") as f:
        return json.load(f)

# ============================================
# STATISTICAL MODELS (REAL FORECASTING)
# ============================================
try:
    from statsmodels.tsa.holtwinters import ExponentialSmoothing
    from statsmodels.tsa.arima.model import ARIMA
    from statsmodels.tsa.seasonal import seasonal_decompose
    from statsmodels.tsa.stattools import adfuller, acf
    import statsmodels.api as sm
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False
    print("âš ï¸ statsmodels not installed. Install with: pip install statsmodels")

# ============================================
# MACHINE LEARNING (OPTIONAL ENHANCEMENTS)
# ============================================
try:
    from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
    from sklearn.preprocessing import StandardScaler
    from sklearn.model_selection import TimeSeriesSplit
    from sklearn.metrics import mean_absolute_error, mean_squared_error
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# ============================================
# VISUALIZATION & REPORTING
# ============================================
try:
    import matplotlib
    matplotlib.use('Agg')  # Non-interactive backend
    import matplotlib.pyplot as plt
    from matplotlib.backends.backend_pdf import PdfPages
    import seaborn as sns
    MATPLOTLIB_AVAILABLE = True
except ImportError:
    MATPLOTLIB_AVAILABLE = False

try:
    from fpdf import FPDF
    FPDF_AVAILABLE = True
except ImportError:
    FPDF_AVAILABLE = False

# ============================================
# GUI FRAMEWORK (TKINTER)
# ============================================
import tkinter as tk
from tkinter import ttk, filedialog, messagebox, scrolledtext
from tkinter.font import Font
import threading

# ============================================
# DATA INGESTION + SCHEMA VALIDATION
# ============================================
def load_and_validate_data(file_path):
    """
    Load sales data from CSV or Excel file.
    Returns: DataFrame with validated data
    """
    try:
        # Load data based on file extension
        if str(file_path).lower().endswith('.csv'):
            sales_df = pd.read_csv(file_path)
        elif str(file_path).lower().endswith(('.xlsx', '.xls')):
            sales_df = pd.read_excel(file_path)
        else:
            raise ValueError("Unsupported file format. Use CSV or Excel.")
        
        # Normalize column names (makes Date â†’ date, Product â†’ product, etc.)
        sales_df.columns = sales_df.columns.str.strip().str.lower()
        
        # Validate required columns
        required_cols = {"date", "product", "sales"}
        if not required_cols.issubset(sales_df.columns):
            raise ValueError(f"Missing required columns. Need: {required_cols}. Found: {sales_df.columns.tolist()}")
        
        # Convert types
        sales_df["date"] = pd.to_datetime(sales_df["date"])
        sales_df["product"] = sales_df["product"].astype(str)
        sales_df["sales"] = pd.to_numeric(sales_df["sales"], errors="coerce").fillna(0)
        
        print(f"âœ… Data loaded: {len(sales_df)} rows, {sales_df['product'].nunique()} products")
        return sales_df
        
    except Exception as e:
        raise Exception(f"Failed to load data: {str(e)}")

# ============================================
# PREPROCESSING WITH ENHANCED ANALYSIS
# ============================================
def preprocess_data(sales_df):
    """Resample data to monthly frequency with additional features."""
    sales_df = sales_df.sort_values("date")
    
    monthly_df = (
        sales_df
        .set_index("date")
        .groupby("product")["sales"]
        .resample("ME")  # Month End
        .sum()
        .reset_index()
    )
    
    print(f"âœ… Monthly resampling complete: {monthly_df['product'].nunique()} products")
    return monthly_df

# ============================================
# ENTERPRISE FORECASTING ENGINE
# ============================================
class ForecastHubEngine:
    """Advanced forecasting engine with multiple models"""
    
    def __init__(self, config=None):
        self.config = config or load_config()
        self.forecast_horizon = self.config.get("forecast_horizon", 12)
        self.confidence_level = self.config.get("confidence_level", 0.95)
        self.min_data_months = self.config.get("min_data_months", 6)
        self.results = {}
        
    def analyze_data_quality(self, df):
        """Comprehensive data quality assessment"""
        analysis = {
            'total_rows': len(df),
            'date_range': (df['date'].min(), df['date'].max()),
            'products': df['product'].nunique(),
            'data_gaps': None,
            'outliers': None,
            'completeness': {}
        }
        
        # Check for missing dates
        if len(df) > 0:
            date_range = pd.date_range(start=df['date'].min(), end=df['date'].max(), freq='D')
            missing_dates = date_range.difference(df['date'].unique())
            analysis['data_gaps'] = len(missing_dates)
            
        # Check for outliers using IQR
        Q1 = df['sales'].quantile(0.25)
        Q3 = df['sales'].quantile(0.75)
        IQR = Q3 - Q1
        outliers = df[(df['sales'] < (Q1 - 1.5 * IQR)) | (df['sales'] > (Q3 + 1.5 * IQR))]
        analysis['outliers'] = len(outliers)
        
        return analysis
    
    def detect_seasonality(self, series):
        """Advanced seasonality detection"""
        if len(series) < 24:
            return {'has_seasonality': False, 'period': None, 'strength': 0}
        
        try:
            # Use seasonal decomposition
            decomposition = seasonal_decompose(series, model='additive', period=12)
            seasonal_strength = 1 - (decomposition.resid.var() / decomposition.observed.var())
            
            # Use autocorrelation
            autocorr = acf(series, nlags=24, fft=True)
            seasonal_lags = [12, 24]
            max_autocorr = max(abs(autocorr[12]), abs(autocorr[min(24, len(autocorr)-1)]))
            
            return {
                'has_seasonality': seasonal_strength > 0.3 or max_autocorr > 0.3,
                'period': 12,  # Monthly data
                'strength': round(max(seasonal_strength, max_autocorr), 3),
                'peak_month': series.groupby(series.index.month).mean().idxmax(),
                'trough_month': series.groupby(series.index.month).mean().idxmin()
            }
        except:
            return {'has_seasonality': False, 'period': None, 'strength': 0}
    
    def calculate_trend_metrics(self, series):
        """Calculate comprehensive trend metrics"""
        if len(series) < 3:
            return {'direction': 'insufficient_data', 'strength': 0, 'slope': 0}
        
        # Linear trend
        x = np.arange(len(series))
        y = series.values
        slope, intercept = np.polyfit(x, y, 1)
        
        # R-squared for trend strength
        y_pred = slope * x + intercept
        ss_res = np.sum((y - y_pred) ** 2)
        ss_tot = np.sum((y - np.mean(y)) ** 2)
        r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0
        
        # Recent momentum (last 3 months vs previous 3)
        if len(series) >= 6:
            recent = series.iloc[-3:].mean()
            previous = series.iloc[-6:-3].mean()
            momentum = ((recent - previous) / previous * 100) if previous != 0 else 0
        else:
            momentum = 0
        
        direction = 'up' if slope > 0 else 'down' if slope < 0 else 'flat'
        
        return {
            'direction': direction,
            'strength': round(r_squared, 3),
            'slope': round(slope, 2),
            'momentum': round(momentum, 1),
            'volatility': round(series.pct_change().std() * np.sqrt(12), 3)  # Annualized
        }
    
    def calculate_real_weights(self, series, individual_forecasts):
        """Calculate REAL ensemble weights based on model performance"""
        weights = {}
        model_errors = {}
        
        # Only evaluate models that produced forecasts
        valid_models = {k: v for k, v in individual_forecasts.items() 
                       if v is not None and len(v) > 0 and not v.isna().any()}
        
        if len(valid_models) == 0:
            # No valid models, equal weights
            return {'trend': 1.0}
        
        # Use time series cross-validation to evaluate each model
        for model_name, forecast in valid_models.items():
            try:
                # Simple backtesting: train on first 2/3, test on last 1/3
                if len(series) >= 12:
                    split_idx = int(len(series) * 0.67)
                    train = series.iloc[:split_idx]
                    test = series.iloc[split_idx:]
                    
                    # Re-train model on training data
                    if model_name == 'holt_winters' and STATSMODELS_AVAILABLE:
                        if len(train) >= 12:
                            seasonal_info = self.detect_seasonality(train)
                            if seasonal_info['has_seasonality'] and len(train) >= 24:
                                model = ExponentialSmoothing(
                                    train, seasonal_periods=12, trend='add', seasonal='add'
                                ).fit()
                            else:
                                model = ExponentialSmoothing(train, trend='add', seasonal=None).fit()
                            
                            # Forecast same horizon as test
                            fc_horizon = len(test)
                            test_forecast = model.forecast(fc_horizon)
                            
                            # Calculate RMSE
                            error = np.sqrt(mean_squared_error(test.values, test_forecast.values))
                            model_errors[model_name] = error
                    
                    elif model_name == 'arima' and STATSMODELS_AVAILABLE:
                        if len(train) >= 6:
                            model = ARIMA(train, order=(1,1,1)).fit()
                            test_forecast = model.forecast(len(test))
                            error = np.sqrt(mean_squared_error(test.values, test_forecast.values))
                            model_errors[model_name] = error
                    
                    elif model_name == 'machine_learning' and SKLEARN_AVAILABLE:
                        # Simplified ML backtest
                        if len(train) >= 12:
                            # Create features for last part of training
                            X_train = []
                            y_train = []
                            
                            for i in range(6, len(train)):
                                X_train.append([
                                    train.iloc[i-1], train.iloc[i-2], train.iloc[i-3],
                                    train.iloc[i-1] - train.iloc[i-2],
                                    train.iloc[i-2] - train.iloc[i-3],
                                    train.iloc[i-6:i-1].mean()
                                ])
                                y_train.append(train.iloc[i])
                            
                            if len(X_train) > 0:
                                model_rf = RandomForestRegressor(n_estimators=50, random_state=42)
                                model_rf.fit(X_train, y_train)
                                
                                # Forecast test period
                                test_forecast = []
                                last_values = train.iloc[-6:].tolist()
                                
                                for _ in range(len(test)):
                                    features = [
                                        last_values[-1], last_values[-2], last_values[-3],
                                        last_values[-1] - last_values[-2],
                                        last_values[-2] - last_values[-3],
                                        np.mean(last_values[-6:])
                                    ]
                                    pred = model_rf.predict([features])[0]
                                    test_forecast.append(pred)
                                    last_values.append(pred)
                                    last_values = last_values[-6:]
                                
                                error = np.sqrt(mean_squared_error(test.values, test_forecast))
                                model_errors[model_name] = error
                
            except Exception as e:
                print(f"Model evaluation failed for {model_name}: {e}")
                continue
        
        # Calculate weights inversely proportional to error
        if model_errors:
            # Inverse error weighting (lower error = higher weight)
            inv_errors = {k: 1.0 / (v + 1e-10) for k, v in model_errors.items()}
            total_inv = sum(inv_errors.values())
            weights = {k: v / total_inv for k, v in inv_errors.items()}
        else:
            # Equal weights if no errors calculated
            equal_weight = 1.0 / len(valid_models)
            weights = {k: equal_weight for k in valid_models.keys()}
        
        return weights
        
        
    def generate_ensemble_forecast(self, series):
        """Generate forecast using ensemble of models - NO HARD-CODING"""
        forecasts = {}
        model_weights = {}
        
        # 1. Enhanced Exponential Smoothing (Holt-Winters)
        if STATSMODELS_AVAILABLE and len(series) >= 12:
            try:
                seasonal_info = self.detect_seasonality(series)
                
                if seasonal_info['has_seasonality'] and len(series) >= 24:
                    # Test both additive and multiplicative seasonality
                    try:
                        model_add = ExponentialSmoothing(
                            series,
                            seasonal_periods=12,
                            trend='add',
                            seasonal='add'
                        ).fit()
                        
                        model_mul = ExponentialSmoothing(
                            series,
                            seasonal_periods=12,
                            trend='add',
                            seasonal='mul'
                        ).fit()
                        
                        # Use model with lower AIC (better fit)
                        if model_mul.aic < model_add.aic:
                            model = model_mul
                        else:
                            model = model_add
                            
                    except Exception as e:
                        # Fallback to additive if multiplicative fails
                        model = ExponentialSmoothing(
                            series,
                            seasonal_periods=12,
                            trend='add',
                            seasonal='add'
                        ).fit()
                else:
                    # Non-seasonal model
                    model = ExponentialSmoothing(
                        series,
                        trend='add',
                        seasonal=None
                    ).fit()
                
                fc_hw = model.forecast(self.forecast_horizon)
                
                # Check for NaN in Holt-Winters forecast
                if not fc_hw.isna().any():
                    forecasts['holt_winters'] = fc_hw
                    
                    # ========== ADD THIS WEIGHT CALCULATION ==========
                    # Calculate weight based on normalized AIC (NO hard-coded /1000)
                    # Compare to naive model AIC baseline
                    naive_variance = series.var()
                    if naive_variance > 0:
                        naive_log_likelihood = -0.5 * len(series) * (np.log(2 * np.pi * naive_variance) + 1)
                        naive_aic = 2 * 1 - 2 * naive_log_likelihood  # 1 parameter for mean
                        
                        if model.aic > 0 and naive_aic > 0:
                            # Weight inversely proportional to AIC improvement over naive
                            aic_improvement = (naive_aic - model.aic) / naive_aic
                            model_weights['holt_winters'] = max(0.1, aic_improvement)
                        else:
                            # Fallback: use model fit quality
                            model_weights['holt_winters'] = 0.5
                    else:
                        model_weights['holt_winters'] = 0.5
                    
                    # Calculate weight based on normalized AIC (NO hard-coded /1000)
                    # Compare to naive model AIC baseline
                    naive_variance = series.var()
                    if naive_variance > 0:
                        naive_log_likelihood = -0.5 * len(series) * (np.log(2 * np.pi * naive_variance) + 1)
                        naive_aic = 2 * 1 - 2 * naive_log_likelihood  # 1 parameter for mean
                        
                        if model.aic > 0 and naive_aic > 0:
                            # Weight inversely proportional to AIC improvement over naive
                            aic_improvement = (naive_aic - model.aic) / naive_aic
                            model_weights['holt_winters'] = max(0.1, aic_improvement)
                        else:
                            # Fallback: use model fit quality (higher likelihood = higher weight)
                            model_weights['holt_winters'] = 0.5
                    else:
                        model_weights['holt_winters'] = 0.5
                else:
                    print("Holt-Winters produced NaN values")
            except Exception as e:
                print(f"Holt-Winters failed: {e}")
        
        # 2. Simple Auto-ARIMA
        if STATSMODELS_AVAILABLE and len(series) >= 6:
            try:
                best_model = None
                best_aic = np.inf
                best_order = (1,1,1)  # Default fallback
                
                # Simple grid search for optimal (p,d,q) parameters
                # Only test common orders to avoid overfitting
                test_orders = [
                    (0,1,0),  # Random walk
                    (1,1,0),  # AR(1)
                    (0,1,1),  # MA(1)
                    (1,1,1),  # ARMA(1,1) - your original
                    (2,1,0),  # AR(2)
                    (0,1,2),  # MA(2)
                    (1,0,0),  # AR(1) no differencing
                    (0,0,1)   # MA(1) no differencing
                ]
                
                for order in test_orders:
                    try:
                        # Ensure enough data for this order
                        min_data_needed = 5 * (order[0] + order[1] + order[2] + 1)
                        if len(series) >= min_data_needed:
                            model_test = ARIMA(series, order=order).fit()
                            if model_test.aic < best_aic and not np.isnan(model_test.aic):
                                best_aic = model_test.aic
                                best_model = model_test
                                best_order = order
                    except:
                        continue
                
                # Use best model found, or fallback to default
                if best_model is not None:
                    model_arima = best_model
                    fc_arima = model_arima.forecast(self.forecast_horizon)
                else:
                    # Fallback to default
                    model_arima = ARIMA(series, order=(1,1,1)).fit()
                    fc_arima = model_arima.forecast(self.forecast_horizon)
                
                # Check for NaN in ARIMA forecast
                if not fc_arima.isna().any():
                    forecasts['arima'] = fc_arima
                    
                    # Calculate weight based on normalized AIC (NO hard-coded /1000)
                    # Compare to naive model
                    naive_variance = series.var()
                    if naive_variance > 0:
                        naive_log_likelihood = -0.5 * len(series) * (np.log(2 * np.pi * naive_variance) + 1)
                        naive_aic = 2 * 3 - 2 * naive_log_likelihood  # ARIMA(1,1,1) has 3 params
                        
                        if model_arima.aic > 0 and naive_aic > 0:
                            aic_improvement = (naive_aic - model_arima.aic) / naive_aic
                            model_weights['arima'] = max(0.1, aic_improvement)
                        else:
                            model_weights['arima'] = 0.5
                    else:
                        model_weights['arima'] = 0.5
                else:
                    print("ARIMA produced NaN values")
                    
            except Exception as e:
                print(f"ARIMA failed: {e}")
        
        # 3. Machine Learning (Random Forest)
        if SKLEARN_AVAILABLE and len(series) >= 12:
            try:
                # Create features for ML
                X = []
                y = []
                
                for i in range(6, len(series)):
                    moving_avg = series.iloc[i-6:i-1].mean()
                    ratio_feature = series.iloc[i-1] / max(abs(moving_avg), 0.0001) if abs(moving_avg) > 0.0001 else 1.0
                    
                    X.append([
                        series.iloc[i-1],  # Lag 1
                        series.iloc[i-2],  # Lag 2
                        series.iloc[i-3],  # Lag 3
                        series.iloc[i-1] - series.iloc[i-2],  # Difference 1
                        series.iloc[i-2] - series.iloc[i-3],  # Difference 2
                        moving_avg,  # Moving average
                        ratio_feature  # Ratio
                    ])
                    y.append(series.iloc[i])
                
                X = np.array(X)
                y = np.array(y)
                
                # Check for NaN in features or target
                if len(X) > 0 and not np.isnan(X).any() and not np.isnan(y).any():
                    model_rf = RandomForestRegressor(n_estimators=100, random_state=42)
                    model_rf.fit(X, y)
                    
                    # Generate forecast recursively
                    last_values = series.iloc[-6:].tolist()
                    ml_forecast = []
                    
                    for _ in range(self.forecast_horizon):
                        recent_avg = np.mean(last_values[-6:])
                        forecast_ratio = last_values[-1] / max(abs(recent_avg), 0.0001) if abs(recent_avg) > 0.0001 else 1.0
                        
                        features = [
                            last_values[-1],
                            last_values[-2],
                            last_values[-3],
                            last_values[-1] - last_values[-2],
                            last_values[-2] - last_values[-3],
                            recent_avg,
                            forecast_ratio
                        ]
                        
                        prediction = model_rf.predict([features])[0]
                        
                        # Ensure prediction is not NaN or infinite
                        if np.isnan(prediction) or np.isinf(prediction):
                            prediction = last_values[-1]  # Fallback to last value
                        
                        ml_forecast.append(prediction)
                        last_values.append(prediction)
                        last_values = last_values[-6:]  # Keep only last 6
                    
                    forecasts['machine_learning'] = pd.Series(ml_forecast)
                    
                    # Calculate ML weight based on out-of-sample performance
                    # Use time series cross-validation if enough data
                    if len(series) >= 24:
                        from sklearn.model_selection import TimeSeriesSplit
                        from sklearn.metrics import mean_squared_error
                        
                        tscv = TimeSeriesSplit(n_splits=min(3, len(series)//8))
                        ml_errors = []
                        
                        for train_idx, test_idx in tscv.split(series):
                            if len(train_idx) >= 12 and len(test_idx) >= 3:
                                train = series.iloc[train_idx]
                                test = series.iloc[test_idx]
                                
                                # Re-train ML on training fold
                                X_train = []
                                y_train = []
                                
                                for i in range(6, len(train)):
                                    train_moving_avg = train.iloc[i-6:i-1].mean()
                                    train_ratio = train.iloc[i-1] / max(abs(train_moving_avg), 0.0001) if abs(train_moving_avg) > 0.0001 else 1.0
                                    
                                    X_train.append([
                                        train.iloc[i-1],
                                        train.iloc[i-2],
                                        train.iloc[i-3],
                                        train.iloc[i-1] - train.iloc[i-2],
                                        train.iloc[i-2] - train.iloc[i-3],
                                        train_moving_avg,
                                        train_ratio
                                    ])
                                    y_train.append(train.iloc[i])
                                
                                if len(X_train) > 0:
                                    fold_model = RandomForestRegressor(n_estimators=50, random_state=42)
                                    fold_model.fit(X_train, y_train)
                                    
                                    # Forecast test period
                                    fold_forecast = []
                                    fold_last_values = train.iloc[-6:].tolist()
                                    
                                    for _ in range(len(test)):
                                        fold_recent_avg = np.mean(fold_last_values[-6:])
                                        fold_ratio = fold_last_values[-1] / max(abs(fold_recent_avg), 0.0001) if abs(fold_recent_avg) > 0.0001 else 1.0
                                        
                                        fold_features = [
                                            fold_last_values[-1],
                                            fold_last_values[-2],
                                            fold_last_values[-3],
                                            fold_last_values[-1] - fold_last_values[-2],
                                            fold_last_values[-2] - fold_last_values[-3],
                                            fold_recent_avg,
                                            fold_ratio
                                        ]
                                        
                                        fold_pred = fold_model.predict([fold_features])[0]
                                        fold_forecast.append(fold_pred)
                                        fold_last_values.append(fold_pred)
                                        fold_last_values = fold_last_values[-6:]
                                    
                                    # Calculate RMSE
                                    if len(fold_forecast) == len(test):
                                        error = np.sqrt(mean_squared_error(test.values, fold_forecast))
                                        ml_errors.append(error)
                        
                        if ml_errors:
                            # Weight inversely proportional to average error
                            avg_error = np.mean(ml_errors)
                            series_mean = abs(series.mean())
                            if series_mean > 0:
                                normalized_error = avg_error / series_mean
                                model_weights['machine_learning'] = 1.0 / (1.0 + normalized_error)
                            else:
                                model_weights['machine_learning'] = 0.5
                        else:
                            # Fallback to forecast stability
                            fc_series = pd.Series(ml_forecast)
                            fc_cv = fc_series.std() / max(abs(fc_series.mean()), 0.0001)
                            model_weights['machine_learning'] = 1.0 / (1.0 + fc_cv)
                    else:
                        # Not enough data for CV, use forecast stability
                        fc_series = pd.Series(ml_forecast)
                        fc_cv = fc_series.std() / max(abs(fc_series.mean()), 0.0001)
                        model_weights['machine_learning'] = 1.0 / (1.0 + fc_cv)
                else:
                    print("ML features contain NaN values")
            except Exception as e:
                print(f"ML failed: {e}")
        
        # 4. Statistical fallback (NO hard-coded 2% growth)
        if len(forecasts) == 0:
            # Calculate actual historical growth characteristics
            if len(series) >= 3:
                # Use median of recent growth rates
                pct_changes = series.pct_change().dropna()
                if len(pct_changes) > 0:
                    # Use winsorized median to handle outliers
                    from scipy import stats
                    median_growth = np.median(pct_changes)
                    
                    # Cap extreme growth rates
                    q1, q3 = np.percentile(pct_changes, [25, 75])
                    iqr = q3 - q1
                    lower_bound = q1 - 1.5 * iqr
                    upper_bound = q3 + 1.5 * iqr
                    median_growth = np.clip(median_growth, lower_bound, upper_bound)
                else:
                    median_growth = 0
                
                # Simple projection with diminishing returns
                last_value = series.iloc[-1]
                simple_fc = []
                
                for i in range(1, self.forecast_horizon + 1):
                    # Trend diminishes over time (more realistic)
                    decay_factor = 0.8 ** (i / 3)  # 20% decay per quarter
                    forecast_value = last_value * (1 + median_growth * decay_factor) ** i
                    
                    # Ensure reasonable bounds
                    if forecast_value < 0:
                        forecast_value = last_value * 0.9  # Max 10% decline
                    if forecast_value > last_value * 3:  # Cap at 200% growth
                        forecast_value = last_value * 3
                    
                    simple_fc.append(forecast_value)
                
                forecasts['statistical_fallback'] = pd.Series(simple_fc)
                model_weights['statistical_fallback'] = 0.3  # Lower confidence in fallback
            else:
                # Very little data: use last value with noise
                last_value = series.iloc[-1] if len(series) > 0 else 0
                if last_value > 0:
                    # Add noise proportional to value
                    noise_std = last_value * 0.1
                else:
                    noise_std = 1.0
                
                simple_fc = [last_value + np.random.normal(0, noise_std) for _ in range(self.forecast_horizon)]
                forecasts['naive_fallback'] = pd.Series(simple_fc)
                model_weights['naive_fallback'] = 0.2  # Very low confidence
        
        # Ensemble weighted average with NO hard-coded weights
        if len(forecasts) > 0:
            # If we have calculated weights, use them
            if model_weights:
                total_weight = sum(model_weights.values())
                normalized_weights = {k: v/total_weight for k, v in model_weights.items()}
            else:
                # Equal weights if no weights calculated
                equal_weight = 1.0 / len(forecasts)
                normalized_weights = {k: equal_weight for k in forecasts.keys()}
            
            ensemble_forecast = pd.Series([0.0] * self.forecast_horizon)
            valid_models = 0
            
            for model_name, forecast in forecasts.items():
                weight = normalized_weights.get(model_name, 0)
                
                # Check if forecast contains NaN before adding
                if not forecast.isna().any():
                    ensemble_forecast += forecast.values * weight
                    valid_models += 1
                else:
                    print(f"Model {model_name} forecast contains NaN, skipping")
            
            # If no valid forecasts, return None
            if valid_models == 0:
                return None, {}, {}
            
            # Final NaN check on ensemble forecast
            if ensemble_forecast.isna().any():
                print("Ensemble forecast contains NaN, using fallback")
                # Fallback to simple average of valid forecasts
                valid_forecasts = [f for f in forecasts.values() if not f.isna().any()]
                if valid_forecasts:
                    ensemble_forecast = pd.concat(valid_forecasts, axis=1).mean(axis=1)
                else:
                    return None, {}, {}
            
            return ensemble_forecast, forecasts, normalized_weights
        
        return None, {}, {}    
        

    
    def calculate_confidence_intervals(self, series, forecast, confidence=0.95):
        """
        Calculate REAL statistical prediction intervals using:
        1. Model residuals when available
        2. Bootstrap methods for empirical intervals
        3. Proper error propagation
        NO hard-coded values, NO arbitrary scaling
        """
        import scipy.stats as stats
        
        # Convert to numpy arrays
        series_values = series.values.astype(float)
        forecast_values = forecast.values.astype(float) if hasattr(forecast, 'values') else np.array(forecast, dtype=float)
        
        # Edge case: insufficient data
        if len(series_values) < 6:
            print(f"SCIENTIFIC: Insufficient data ({len(series_values)} points), using conservative intervals")
            
            # With little data, use empirical rule based on historical variation
            if len(series_values) > 1:
                hist_std = np.std(series_values)
                hist_mean = np.mean(series_values)
                
                # Coefficient of Variation (relative uncertainty)
                if abs(hist_mean) > np.finfo(float).eps:
                    cv = hist_std / abs(hist_mean)
                else:
                    cv = 1.0  # Default for near-zero mean
                
                # Prediction interval for new observation:
                # se_pred = s * sqrt(1 + 1/n) for simple linear case
                n = len(series_values)
                se_pred = hist_std * np.sqrt(1 + 1/n)
                
                # t-value for small samples
                df = max(1, n - 1)
                t_val = stats.t.ppf((1 + confidence) / 2, df=df)
                
                margin = t_val * se_pred
                lower = forecast_values - margin
                upper = forecast_values + margin
                
                # Ensure non-negative for sales
                lower = np.maximum(lower, 0)
                
                print(f"SCIENTIFIC: Small sample CI using t-distribution, df={df}, t={t_val:.2f}")
                return lower, upper
            else:
                # Single data point - use wide bounds
                margin = abs(series_values[0]) * 0.5  # 50% of single value
                lower = forecast_values - margin
                upper = forecast_values + margin
                lower = np.maximum(lower, 0)
                return lower, upper
        
        # METHOD 1: Use ARIMA model residuals (if available)
        if STATSMODELS_AVAILABLE and len(series_values) >= 12:
            try:
                # Fit ARIMA model to get residuals
                from statsmodels.tsa.arima.model import ARIMA
                
                # Determine optimal order via information criteria
                best_aic = np.inf
                best_residuals = None
                best_model = None
                
                # Test simple ARIMA orders
                for p in range(3):
                    for d in range(2):
                        for q in range(3):
                            try:
                                if len(series_values) >= max(10, 5*(p+d+q+1)):
                                    model = ARIMA(series_values, order=(p, d, q)).fit()
                                    if model.aic < best_aic and len(model.resid) > 10:
                                        best_aic = model.aic
                                        best_residuals = model.resid
                                        best_model = model
                            except:
                                continue
                
                if best_residuals is not None and len(best_residuals) > 10:
                    residuals = best_residuals[~np.isnan(best_residuals)]
                    sigma = np.std(residuals)  # Residual standard error
                    n = len(series_values)
                    
                    print(f"SCIENTIFIC: Using ARIMA residuals, sigma={sigma:.2f}, n={n}")
                    
                    # Calculate prediction intervals for each horizon
                    # For ARIMA, forecast variance increases with horizon
                    margins = []
                    for h in range(1, len(forecast_values) + 1):
                        # Simplified: variance grows with sqrt(horizon)
                        # More accurate would use model-specific psi-weights
                        var_h = sigma**2 * (1 + (h-1) * 0.1)  # 10% increase per step
                        se_h = np.sqrt(var_h)
                        
                        # Use t-distribution for uncertainty
                        df = n - len(best_model.params) if hasattr(best_model, 'params') else n - 2
                        df = max(1, df)
                        t_val = stats.t.ppf((1 + confidence) / 2, df=df)
                        
                        margins.append(t_val * se_h)
                    
                    lower = forecast_values - np.array(margins)
                    upper = forecast_values + np.array(margins)
                    lower = np.maximum(lower, 0)
                    
                    print(f"SCIENTIFIC: ARIMA-based prediction intervals calculated")
                    return lower, upper
                    
            except Exception as e:
                print(f"SCIENTIFIC: ARIMA method failed: {e}")
        
        # METHOD 2: Exponential Smoothing residuals
        if STATSMODELS_AVAILABLE and len(series_values) >= 8:
            try:
                from statsmodels.tsa.holtwinters import ExponentialSmoothing
                
                # Fit simple exponential smoothing
                model = ExponentialSmoothing(series_values, trend='add').fit()
                residuals = model.resid[~np.isnan(model.resid)]
                
                if len(residuals) >= 10:
                    sigma = np.std(residuals)
                    n = len(series_values)
                    
                    # For exponential smoothing, forecast variance constant
                    se_pred = sigma * np.sqrt(1 + 1/n)
                    
                    # t-value for prediction interval
                    df = n - 2  # Rough degrees of freedom
                    t_val = stats.t.ppf((1 + confidence) / 2, df=df)
                    margin = t_val * se_pred
                    
                    # Constant margin for all horizons (simplification)
                    lower = forecast_values - margin
                    upper = forecast_values + margin
                    lower = np.maximum(lower, 0)
                    
                    print(f"SCIENTIFIC: Exponential Smoothing CI, sigma={sigma:.2f}, margin={margin:.2f}")
                    return lower, upper
                    
            except Exception as e:
                print(f"SCIENTIFIC: Exponential Smoothing failed: {e}")
        
        # METHOD 3: Bootstrapping (most general, always works)
        print("SCIENTIFIC: Using empirical bootstrap for prediction intervals")
        
        # Determine bootstrap sample size based on available data
        n_bootstrap = min(5000, max(100, len(series_values) * 100))
        
        # Bootstrap historical errors
        bootstrap_forecasts = []
        
        for _ in range(n_bootstrap):
            # Sample historical percent changes with replacement
            if len(series_values) >= 2:
                # Use log returns for multiplicative model
                log_returns = np.diff(np.log(series_values + 1e-10))  # Add epsilon to avoid log(0)
                
                if len(log_returns) > 0:
                    # Sample returns
                    sampled_returns = np.random.choice(log_returns, size=len(forecast_values), replace=True)
                    
                    # Generate bootstrap forecast
                    last_value = series_values[-1]
                    bootstrap_fc = [last_value]
                    for ret in sampled_returns:
                        next_val = bootstrap_fc[-1] * np.exp(ret)
                        bootstrap_fc.append(next_val)
                    
                    bootstrap_forecasts.append(bootstrap_fc[1:])
                else:
                    # Fallback: sample from historical values
                    sampled_values = np.random.choice(series_values, size=len(forecast_values), replace=True)
                    bootstrap_forecasts.append(sampled_values)
            else:
                # Very little data
                bootstrap_forecasts.append([series_values[0]] * len(forecast_values))
        
        bootstrap_forecasts = np.array(bootstrap_forecasts)
        
        # Calculate empirical percentiles
        alpha = 1 - confidence
        lower_percentile = 100 * alpha / 2
        upper_percentile = 100 * (1 - alpha / 2)
        
        lower = np.percentile(bootstrap_forecasts, lower_percentile, axis=0)
        upper = np.percentile(bootstrap_forecasts, upper_percentile, axis=0)
        
        # Ensure forecasts are within bounds
        lower = np.minimum(lower, forecast_values)
        upper = np.maximum(upper, forecast_values)
        lower = np.maximum(lower, 0)
        
        print(f"SCIENTIFIC: Bootstrap CI with {n_bootstrap} samples, {confidence*100:.0f}% coverage")
        
        return lower, upper
    
    def calculate_risk_score(self, series, forecast):
        """Calculate enterprise risk score (0-100)"""
        score = 100  # Start with perfect score
        
        # 1. Data sufficiency penalty
        if len(series) < 12:
            score -= 30
        elif len(series) < 24:
            score -= 15
        
        # 2. Volatility penalty
        volatility = series.pct_change().std()
        if volatility > 0.5:
            score -= 25
        elif volatility > 0.2:
            score -= 15
        elif volatility > 0.1:
            score -= 5
        
        # 3. Forecast stability penalty
        forecast_std = forecast.std() / forecast.mean() if forecast.mean() != 0 else 0
        if forecast_std > 0.3:
            score -= 20
        
        # 4. Trend consistency bonus/penalty
        trend = self.calculate_trend_metrics(series)
        if trend['strength'] > 0.7:
            score += 10  # Strong trend is predictable
        elif trend['strength'] < 0.3:
            score -= 10  # Weak trend is unpredictable
        
        # Ensure score is between 0-100
        score = max(0, min(100, score))
        
        # Risk category from config
        thresholds = self.config.get("risk_thresholds", {})
        high_risk = thresholds.get("high_risk", 40)
        medium_risk = thresholds.get("medium_risk", 60)
        low_risk = thresholds.get("low_risk", 80)
        
        if score >= low_risk:
            risk_category = "Low Risk"
            color = "#27AE60"  # Green
        elif score >= medium_risk:
            risk_category = "Moderate Risk"
            color = "#F39C12"  # Orange
        elif score >= high_risk:
            risk_category = "High Risk"
            color = "#E74C3C"  # Red
        else:
            risk_category = "Very High Risk"
            color = "#8B0000"  # Dark red
        
        return {
            'score': round(score),
            'category': risk_category,
            'color': color,
            'volatility': round(volatility, 3),
            'data_sufficiency': len(series),
            'trend_strength': trend['strength']
        }
    
    def generate_insights(self, product_name, series, forecast, analysis):
        """Generate actionable business insights"""
        insights = []
        
        # Growth insights - DATA-DRIVEN THRESHOLDS
        hist_mean = series.mean()
        fc_mean = forecast.mean()
        
        # Calculate ANNUALIZED growth rate for fair comparison
        if len(series) >= 2:
            # Annualized historical growth
            total_months = len(series)
            hist_total_growth = (series.iloc[-1] / series.iloc[0] - 1) * 100 if series.iloc[0] != 0 else 0
            hist_annual_growth = ((1 + hist_total_growth/100) ** (12/total_months) - 1) * 100
            
            # Forecast growth (annualized)
            forecast_months = len(forecast)
            forecast_total_growth = ((fc_mean / hist_mean) - 1) * 100 if hist_mean > 0 else 0
            growth = ((1 + forecast_total_growth/100) ** (12/forecast_months) - 1) * 100
            
            # Calculate thresholds based on historical ANNUALIZED performance
            if len(series) >= 24:  # At least 2 years for reliable annual calculations
                # Calculate annual rolling growth rates
                annual_growth_rates = []
                for i in range(12, len(series)):
                    if series.iloc[i-12] != 0:
                        annual_growth = ((series.iloc[i] / series.iloc[i-12]) - 1) * 100
                        annual_growth_rates.append(annual_growth)
                
                if len(annual_growth_rates) >= 3:
                    high_growth = np.percentile(annual_growth_rates, 75)  # Top 25% annual growth
                    moderate_growth = np.percentile(annual_growth_rates, 50)  # Median annual growth
                    decline = np.percentile(annual_growth_rates, 25)  # Bottom 25% annual growth
                else:
                    # Fallback to config if insufficient annual data
                    thresholds = self.config.get("growth_thresholds", {})
                    high_growth = thresholds.get("high_growth", 20)
                    moderate_growth = thresholds.get("moderate_growth", 10)
                    decline = thresholds.get("decline", -5)
            
            elif len(series) >= 12:  # 1-2 years of data
                # Calculate monthly growth percentiles and annualize
                monthly_growth = series.pct_change().dropna() * 100
                
                if len(monthly_growth) >= 6:
                    # Convert monthly percentiles to annualized (compound growth)
                    monthly_75th = np.percentile(monthly_growth, 75)
                    monthly_50th = np.percentile(monthly_growth, 50)
                    monthly_25th = np.percentile(monthly_growth, 25)
                    
                    high_growth = ((1 + monthly_75th/100) ** 12 - 1) * 100
                    moderate_growth = ((1 + monthly_50th/100) ** 12 - 1) * 100
                    decline = ((1 + monthly_25th/100) ** 12 - 1) * 100
                else:
                    # Fallback to config
                    thresholds = self.config.get("growth_thresholds", {})
                    high_growth = thresholds.get("high_growth", 20)
                    moderate_growth = thresholds.get("moderate_growth", 10)
                    decline = thresholds.get("decline", -5)
            
            else:  # Less than 12 months
                # Use data variability to set thresholds
                monthly_growth = series.pct_change().dropna() * 100
                
                if len(monthly_growth) >= 3:
                    # Use coefficient of variation (relative volatility)
                    series_mean = abs(series.mean())
                    if series_mean > 0:
                        cv = series.std() / series_mean
                    else:
                        cv = 1.0
                    
                    # Scale thresholds based on volatility
                    high_growth = max(20, cv * 100)  # More conservative for annual
                    moderate_growth = cv * 50
                    decline = -cv * 100
                else:
                    # Minimal data - fallback to config
                    thresholds = self.config.get("growth_thresholds", {})
                    high_growth = thresholds.get("high_growth", 20)
                    moderate_growth = thresholds.get("moderate_growth", 10)
                    decline = thresholds.get("decline", -5)
        
        else:  # Insufficient data (<2 months)
            growth = 0
            # Use config thresholds
            thresholds = self.config.get("growth_thresholds", {})
            high_growth = thresholds.get("high_growth", 20)
            moderate_growth = thresholds.get("moderate_growth", 10)
            decline = thresholds.get("decline", -5)

        if growth > high_growth:
            insights.append({
                'type': 'High Growth Opportunity',
                'message': f'Expected annual growth: {growth:.1f}% (threshold: {high_growth:.1f}%)',
                'priority': 'High',
                'action': 'Consider increasing inventory and marketing'
            })
            
        elif growth < decline:
            insights.append({
                'type': 'Sales Decline Warning',
                'message': f'Expected annual decline: {abs(growth):.1f}% (threshold: {decline:.1f}%)',
                'priority': 'High',
                'action': 'Review pricing, promotions, or consider product refresh'
            })
        
        # Seasonality insights (KEEP EXISTING CODE)
        seasonality = self.detect_seasonality(series)
        if seasonality['has_seasonality']:
            insights.append({
                'type': 'Seasonal Pattern Detected',
                'message': f'Strong seasonality (strength: {seasonality["strength"]:.2f}). Peaks in month {seasonality["peak_month"]}',
                'priority': 'Medium',
                'action': 'Plan inventory and marketing around seasonal peaks'
            })
        
        # Volatility insights (KEEP EXISTING CODE)
        volatility = series.pct_change().std()
        if volatility > 0.3:
            insights.append({
                'type': 'High Volatility Warning',
                'message': f'High sales volatility ({volatility:.2f}). Difficult to predict accurately.',
                'priority': 'High',
                'action': 'Maintain higher safety stock and monitor closely'
            })
        
        # Data quality insights (KEEP EXISTING CODE)
        if analysis['data_gaps'] and analysis['data_gaps'] > 30:
            insights.append({
                'type': 'Data Quality Issue',
                'message': f'{analysis["data_gaps"]} days of missing data detected',
                'priority': 'Medium',
                'action': 'Improve data collection to enhance forecast accuracy'
            })
        
        return insights
    
    def forecast_product(self, product_data, product_name):
        """Complete forecasting pipeline for a single product"""
        if len(product_data) < self.min_data_months:
            print(f"âš ï¸  Skipping '{product_name}': Only {len(product_data)} months (needs {self.min_data_months})")
            return None
        
        # Prepare time series
        series = product_data.set_index('date')['sales'].sort_index()
        
        # Data quality analysis
        data_quality = self.analyze_data_quality(product_data)
        
        # Generate ensemble forecast
        ensemble_fc, individual_fc, weights = self.generate_ensemble_forecast(series)
        
        if ensemble_fc is None:
            print(f"âš ï¸  No forecast generated for '{product_name}'")
            return None
        
        # Forecast dates
        forecast_dates = pd.date_range(
            start=series.index[-1] + pd.offsets.MonthEnd(1),
            periods=self.forecast_horizon,
            freq='M'
        )
        
        # Calculate confidence intervals
        lower_bound, upper_bound = self.calculate_confidence_intervals(
            series, ensemble_fc, self.confidence_level
        )
        
        # Calculate risk score
        risk_assessment = self.calculate_risk_score(series, ensemble_fc)
        
        # Generate insights
        insights = self.generate_insights(product_name, series, ensemble_fc, data_quality)
        
        # Trend analysis
        trend_metrics = self.calculate_trend_metrics(series)
        seasonality = self.detect_seasonality(series)
        
        return {
            'product': product_name,
            'historical_data': series,
            'forecast': pd.Series(ensemble_fc.values, index=forecast_dates),
            'lower_bound': pd.Series(lower_bound, index=forecast_dates),
            'upper_bound': pd.Series(upper_bound, index=forecast_dates),
            'individual_models': individual_fc,
            'model_weights': weights,
            'risk_assessment': risk_assessment,
            'insights': insights,
            'trend_metrics': trend_metrics,
            'seasonality': seasonality,
            'data_quality': data_quality,
            'confidence_level': self.confidence_level,
            'statistics': {
                'historical_mean': series.mean(),
                'historical_std': series.std(),
                'forecast_mean': ensemble_fc.mean(),
                'forecast_std': ensemble_fc.std(),
                'expected_growth': ((ensemble_fc.mean() / series.mean()) - 1) * 100 if series.mean() > 0 else 0,
                'total_historical_months': len(series)
            }
        }
    
    def run_forecast(self, input_file, callback=None):
        """Main forecasting pipeline"""
        try:
            results = {
                'products': [],
                'summary': {},
                'files': {},
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # Load data
            if callback: callback("Loading data...", 10)
            
            df = load_and_validate_data(input_file)
            
            # Check if we have enough data
            if len(df) < self.min_data_months:
                raise Exception(f"Insufficient data. Need at least {self.min_data_months} months of data, got {len(df)} rows.")
            
            # Check for unique products
            unique_products = df['product'].nunique()
            if unique_products == 0:
                raise Exception("No products found in the data.")
            
            if callback: 
                callback(f"Found {len(df)} rows, {unique_products} products", 15)
            
            # Prepare monthly data
            if callback: callback("Preparing data...", 20)
            
            monthly_data = preprocess_data(df)
            
            # Check if monthly data has enough months
            if len(monthly_data) < self.min_data_months:
                raise Exception(f"Insufficient monthly data after processing. Need at least {self.min_data_months} months.")
            
            # Forecast each product
            products = monthly_data['product'].unique()
            total_products = len(products)
            
            if callback: callback(f"Forecasting {total_products} products...", 25)
            
            for idx, product in enumerate(products):
                if callback: 
                    progress = 30 + (idx / total_products * 50)
                    callback(f"Forecasting {product} ({idx+1}/{total_products})...", progress)
                
                product_data = monthly_data[monthly_data['product'] == product]
                result = self.forecast_product(product_data, product)
                
                if result:
                    results['products'].append(result)
            
            # Check if any forecasts were generated
            if not results['products']:
                # Provide detailed error message
                error_details = []
                for product in products:
                    product_data = monthly_data[monthly_data['product'] == product]
                    if len(product_data) < self.min_data_months:
                        error_details.append(f"- '{product}': Only {len(product_data)} months of data (needs {self.min_data_months})")
                    else:
                        error_details.append(f"- '{product}': {len(product_data)} months - should have worked")
                
                error_msg = "No valid forecasts generated. Possible reasons:\n"
                error_msg += "\n".join(error_details)
                error_msg += f"\n\nMinimum data requirement: {self.min_data_months} months per product"
                raise Exception(error_msg)
            
            # Generate summary
            if results['products']:
                results['summary'] = self.generate_summary(results['products'])
            
            return results
            
        except Exception as e:
            raise Exception(f"Forecasting error: {str(e)}")
    
    def generate_summary(self, products):
        """Generate executive summary"""
        total_products = len(products)
        high_risk = sum(1 for p in products if p['risk_assessment']['score'] < 60)
        
        # Use config threshold for high growth
        thresholds = self.config.get("growth_thresholds", {})
        high_growth_threshold = thresholds.get("high_growth", 20)
        high_growth = sum(1 for p in products if p['statistics']['expected_growth'] > high_growth_threshold)
        
        total_insights = sum(len(p['insights']) for p in products)
        avg_risk_score = np.mean([p['risk_assessment']['score'] for p in products])
        
        # Find top/bottom performers
        if products:
            top_growth = max(products, key=lambda x: x['statistics']['expected_growth'])
            top_risk = min(products, key=lambda x: x['risk_assessment']['score'])
        else:
            top_growth = top_risk = None
        
        return {
            'total_products': total_products,
            'products_forecasted': len(products),
            'high_risk_products': high_risk,
            'high_growth_products': high_growth,
            'average_risk_score': round(avg_risk_score, 1),
            'total_insights': total_insights,
            'forecast_months': self.forecast_horizon,
            'confidence_level': self.confidence_level,
            'top_performer': top_growth['product'] if top_growth else None,
            'highest_risk': top_risk['product'] if top_risk else None,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

# ============================================
# REPORT GENERATORS
# ============================================
class ForecastHubReports:
    """Generate reports in multiple formats"""
    
    def __init__(self, output_dir):
        # Fix path handling
        try:
            self.output_dir = Path(output_dir).resolve()
            # Create directory with parents if needed
            self.output_dir.mkdir(parents=True, exist_ok=True)
            print(f"âœ… Output directory: {self.output_dir}")
        except Exception as e:
            # Fallback to script directory if provided path fails
            print(f"âš ï¸  Output directory error: {e}, using default")
            self.output_dir = SCRIPT_DIR / "forecast_reports"
            self.output_dir.mkdir(parents=True, exist_ok=True)
    
    def clean_text(self, text):
        """Clean text by replacing problematic Unicode characters"""
        if not isinstance(text, str):
            return text
        # Replace problematic Unicode characters with safe alternatives
        text = text.replace('\u2022', '-')  # Bullet
        text = text.replace('â€¢', '-')       # Bullet (different representation)
        text = text.replace('â€“', '-')       # En dash
        text = text.replace('â€”', '-')       # Em dash
        text = text.replace('â‚¬', 'EUR')     # Euro
        return text
        
    def generate_csv_report(self, results, filename="forecasthub_monthly.csv"):
        """Generate CSV report"""
        output_path = self.output_dir / filename
        
        try:
            # Create combined dataframe
            rows = []
            for product in results['products']:
                # Clean product name
                product_name = self.clean_text(str(product['product']))
                
                # ================== FORECAST DATA ==================
                for date, value in product['forecast'].items():
                    # Calculate margin of error for FORECAST
                    ci_pct = 0
                    if not (pd.isna(value) or abs(value) < 0.0001 or pd.isna(product['upper_bound'][date])):
                        ci_pct = round((product['upper_bound'][date] - value)/abs(value)*100, 1)
                    
                    rows.append({
                        'product': product_name,
                        'date': date,
                        'sales': round(value, 2),
                        'type': 'forecast',
                        'lower_bound': round(product['lower_bound'][date], 2),
                        'upper_bound': round(product['upper_bound'][date], 2),
                        'margin_of_error': f"Â±{ci_pct}%",
                        'confidence_level': f"{int(product['confidence_level']*100)}%",
                        'sort_order': 1,  # Forecast comes first
                        'sort_date': date  # For sorting
                    })
                
                # ================== HISTORICAL DATA ==================
                for date, value in product['historical_data'].items():
                    rows.append({
                        'product': product_name,
                        'date': date,
                        'sales': round(value, 2),
                        'type': 'historical',
                        'lower_bound': None,
                        'upper_bound': None,
                        'margin_of_error': None,
                        'confidence_level': None,
                        'sort_order': 2,  # Historical comes second
                        'sort_date': date  # For sorting
                    })
            
            # Create DataFrame and SORT
            df = pd.DataFrame(rows)
            
            if len(df) > 0:
                # Sort: 1) sort_order (forecast first), 2) product, 3) date DESC
                df = df.sort_values(
                    by=['sort_order', 'product', 'sort_date'],
                    ascending=[True, True, False]  # Dates DESC = most recent first
                )
                
                # Drop temporary columns and format date
                df = df.drop(columns=['sort_order', 'sort_date'])
                df['date'] = df['date'].dt.strftime('%Y-%m-%d')
                
                # Save to CSV
                df.to_csv(output_path, index=False, encoding='utf-8-sig')
                print(f"âœ… CSV report saved: {output_path}")
                return output_path
            else:
                print("âš ï¸ No data to write to CSV")
                return None
                
        except Exception as e:
            raise Exception(f"Failed to generate CSV report: {str(e)}")
    
    def generate_excel_report(self, results, filename="forecasthub_report.xlsx"):
        """Generate comprehensive Excel report"""
        output_path = self.output_dir / filename
        
        try:
            with pd.ExcelWriter(output_path, engine='openpyxl') as writer:
                # Sheet 1: Sales Data
                sales_rows = []
                for product in results['products']:
                    product_name = self.clean_text(str(product['product']))
                    
                    # Forecast data first
                    for date, value in product['forecast'].items():
                        ci_pct = 0
                        if not (pd.isna(value) or abs(value) < 0.0001 or pd.isna(product['upper_bound'][date])):
                            ci_pct = round((product['upper_bound'][date] - value)/abs(value)*100, 1)
                        
                        sales_rows.append({
                            'Product': product_name,
                            'Date': date,
                            'Sales': round(value, 2),
                            'Type': 'Forecast',
                            'Lower_Bound': round(product['lower_bound'][date], 2),
                            'Upper_Bound': round(product['upper_bound'][date], 2),
                            'Margin_Of_Error': f"Â±{ci_pct}%",
                            'Confidence_Level': f"{int(product['confidence_level']*100)}%"
                        })
                    
                    # Historical data second
                    for date, value in product['historical_data'].items():
                        sales_rows.append({
                            'Product': product_name,
                            'Date': date,
                            'Sales': round(value, 2),
                            'Type': 'Historical',
                            'Lower_Bound': None,
                            'Upper_Bound': None,
                            'Margin_Of_Error': None,
                            'Confidence_Level': None
                        })
                
                if sales_rows:
                    sales_df = pd.DataFrame(sales_rows)
                    # Sort by Product, then Type (Forecast first), then Date (descending)
                    sales_df['Type_Order'] = sales_df['Type'].map({'Forecast': 1, 'Historical': 2})
                    sales_df = sales_df.sort_values(['Type_Order', 'Product', 'Date'], 
                                                   ascending=[True, True, False])
                    sales_df = sales_df.drop(columns=['Type_Order'])
                    sales_df.to_excel(writer, sheet_name='Sales Data', index=False)
                
                # Sheet 2: Product Summary
                summary_rows = []
                for product in results['products']:
                    product_name = self.clean_text(str(product['product']))
                    summary_rows.append({
                        'Product': product_name,
                        'Historical_Months': product['statistics']['total_historical_months'],
                        'Historical_Mean': round(product['statistics']['historical_mean'], 2),
                        'Forecast_Mean': round(product['statistics']['forecast_mean'], 2),
                        'Expected_Growth_%': round(product['statistics']['expected_growth'], 1),
                        'Trend_Direction': product['trend_metrics']['direction'],
                        'Has_Seasonality': product['seasonality']['has_seasonality']
                    })
                
                if summary_rows:
                    pd.DataFrame(summary_rows).to_excel(writer, sheet_name='Product Summary', index=False)
                
                # Sheet 3: Executive Summary
                exec_summary = results['summary']
                exec_data = pd.DataFrame({
                    'Metric': [
                        'Total Products Analyzed',
                        'Products Successfully Forecasted',
                        'High Growth Products',
                        'Total Insights Generated',
                        'Forecast Horizon (Months)',
                        'Confidence Level',
                        'Top Performing Product',
                        'Report Generated'
                    ],
                    'Value': [
                        exec_summary['total_products'],
                        exec_summary['products_forecasted'],
                        exec_summary['high_growth_products'],
                        exec_summary['total_insights'],
                        exec_summary['forecast_months'],
                        f"{exec_summary['confidence_level']*100}%",
                        str(self.clean_text(exec_summary['top_performer'] or 'N/A')),
                        exec_summary['timestamp']
                    ]
                })
                exec_data.to_excel(writer, sheet_name='Executive Summary', index=False)
                
                # Sheet 4: Insights
                insights_rows = []
                for product in results['products']:
                    product_name = self.clean_text(str(product['product']))
                    for insight in product['insights']:
                        insights_rows.append({
                            'Product': product_name,
                            'Insight_Type': self.clean_text(str(insight['type'])),
                            'Message': self.clean_text(str(insight['message'])),
                            'Priority': insight['priority'],
                            'Recommended_Action': self.clean_text(str(insight['action']))
                        })
                
                if insights_rows:
                    pd.DataFrame(insights_rows).to_excel(writer, sheet_name='Insights', index=False)
            
            print(f"âœ… Excel report saved: {output_path}")
            return output_path
            
        except Exception as e:
            print(f"Excel generation error: {e}")
            import traceback
            traceback.print_exc()
            raise
    
    def generate_pdf_report(self, results, filename="forecasthub_summary.pdf"):
        """Generate professional PDF report"""
        if not FPDF_AVAILABLE:
            raise ImportError("FPDF not installed. Install with: pip install fpdf")
        
        output_path = self.output_dir / filename
        
        class PDFReport(FPDF):
            def header(self):
                self.set_font('Arial', 'B', 16)
                self.cell(0, 10, 'ForecastHub Pro - Executive Report', 0, 1, 'C')
                self.set_font('Arial', '', 10)
                self.cell(0, 10, f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", 0, 1, 'C')
                self.ln(5)
            
            def footer(self):
                self.set_y(-15)
                self.set_font('Arial', 'I', 8)
                self.cell(0, 10, f'Page {self.page_no()}', 0, 0, 'C')
        
        pdf = PDFReport()
        pdf.add_page()
        
        # Executive Summary
        pdf.set_font('Arial', 'B', 14)
        pdf.cell(0, 10, 'Executive Summary', 0, 1)
        pdf.set_font('Arial', '', 10)
        
        summary = results['summary']
        pdf.multi_cell(0, 6, f"""
        Total Products Analyzed: {summary['total_products']}
        Products Successfully Forecasted: {summary['products_forecasted']}
        High Growth Products: {summary['high_growth_products']}
        Forecast Horizon: {summary['forecast_months']} months
        Confidence Level: {summary['confidence_level']*100}%
        """)
        
        pdf.ln(10)
        
        # Top Products
        if results['products']:
            pdf.set_font('Arial', 'B', 12)
            pdf.cell(0, 10, 'Top 5 Products by Expected Growth:', 0, 1)
            pdf.set_font('Arial', '', 10)
            
            top_products = sorted(results['products'], 
                                key=lambda x: x['statistics']['expected_growth'], 
                                reverse=True)[:5]
            
            for product in top_products:
                # Clean product name for PDF
                product_name = str(product['product']).replace('\u2022', '-').replace('â€¢', '-').replace('â€“', '-').replace('â€”', '-')
                pdf.cell(0, 6, f"- {product_name}: {product['statistics']['expected_growth']:.1f}% growth", 0, 1)
        
        pdf.output(str(output_path))
        print(f"âœ… PDF report saved: {output_path}")
        return output_path
    
    def generate_charts(self, results):
        """Generate visualization charts"""
        if not MATPLOTLIB_AVAILABLE:
            return []
        
        chart_dir = self.output_dir / "charts"
        chart_dir.mkdir(exist_ok=True)
        
        chart_files = []
        
        for product in results['products'][:10]:  # Limit to 10 charts
            try:
                fig, ax = plt.subplots(figsize=(12, 6))
                
                # Historical vs Forecast
                ax.plot(product['historical_data'].index, product['historical_data'].values, 
                       'b-', linewidth=2, label='Historical', alpha=0.8)
                ax.plot(product['forecast'].index, product['forecast'].values, 
                       'r--', linewidth=2, label='Forecast')
                ax.fill_between(product['forecast'].index,
                               product['lower_bound'].values,
                               product['upper_bound'].values,
                               alpha=0.2, color='red', label='Confidence Interval')
                
                # Clean title for chart
                title = self.clean_text(str(product['product']))
                ax.set_title(f"Sales Forecast: {title}", fontsize=14, fontweight='bold')
                ax.set_xlabel('Date')
                ax.set_ylabel('Sales')
                ax.legend()
                ax.grid(True, alpha=0.3)
                
                                
                plt.tight_layout()
                
                # Save chart
                safe_name = self.clean_text(str(product['product'])).replace('/', '_').replace('\\', '_')[:50]
                chart_path = chart_dir / f"forecast_{safe_name}.png"
                plt.savefig(chart_path, dpi=150, bbox_inches='tight')
                plt.close()
                
                chart_files.append(chart_path)
                
            except Exception as e:
                print(f"Failed to generate chart for {product['product']}: {e}")
                continue
        
        print(f"âœ… Generated {len(chart_files)} charts")
        return chart_files

# ============================================
# MAIN APPLICATION GUI
# ============================================
class ForecastHubApp:
    """Main desktop application"""
    
    def __init__(self):
        self.root = tk.Tk()
        self.root.title("ForecastHub Pro - Enterprise Sales Forecasting")
        self.root.geometry("900x750")
        
        # Load config
        self.config = load_config()
        
        # Variables
        self.input_file = tk.StringVar()
        self.output_dir = tk.StringVar(value=self.config.get("default_output_dir", str(SCRIPT_DIR / "forecast_reports")))
        self.forecast_months = tk.IntVar(value=self.config.get("forecast_horizon", 12))
        self.confidence_level = tk.DoubleVar(value=self.config.get("confidence_level", 0.95))
        
        # Output formats
        self.output_formats = {
            'CSV': tk.BooleanVar(value=self.config.get("generate_csv", True)),
            'Excel': tk.BooleanVar(value=self.config.get("generate_excel", True)),
            'PDF': tk.BooleanVar(value=self.config.get("generate_pdf", True))
        }
        
        # Results
        self.results = None
        
        # Build UI
        self.build_ui()
        
    def build_ui(self):
        """Build the user interface"""
        # Main container
        main_container = ttk.Frame(self.root, padding="20")
        main_container.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))
        
        # Configure grid weights
        self.root.columnconfigure(0, weight=1)
        self.root.rowconfigure(0, weight=1)
        
        # Header
        header_frame = ttk.Frame(main_container)
        header_frame.grid(row=0, column=0, columnspan=2, pady=(0, 20), sticky=(tk.W, tk.E))
        
        ttk.Label(header_frame, text="ForecastHub Pro", 
                 font=('Segoe UI', 24, 'bold'),
                 foreground=self.config.get("theme_color", "#2C3E50")).pack(side=tk.LEFT)
        
        ttk.Label(header_frame, text="Enterprise Sales Forecasting",
                 font=('Segoe UI', 12),
                 foreground="#7F8C8D").pack(side=tk.LEFT, padx=(10, 0))
        
        # Configuration Frame
        config_frame = ttk.LabelFrame(main_container, text="Configuration", padding="15")
        config_frame.grid(row=1, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), padx=(0, 10))
        config_frame.columnconfigure(1, weight=1)
        
        row = 0
        
        # Input File Selection
        ttk.Label(config_frame, text="Sales Data File:").grid(row=row, column=0, sticky=tk.W, pady=5)
        ttk.Entry(config_frame, textvariable=self.input_file, width=40).grid(row=row, column=1, sticky=(tk.W, tk.E), padx=(5, 5), pady=5)
        ttk.Button(config_frame, text="Browse...", command=self.browse_input_file).grid(row=row, column=2, padx=(0, 0), pady=5)
        row += 1
        
        # Output Directory
        ttk.Label(config_frame, text="Output Directory:").grid(row=row, column=0, sticky=tk.W, pady=5)
        ttk.Entry(config_frame, textvariable=self.output_dir, width=40).grid(row=row, column=1, sticky=(tk.W, tk.E), padx=(5, 5), pady=5)
        ttk.Button(config_frame, text="Browse...", command=self.browse_output_dir).grid(row=row, column=2, padx=(0, 0), pady=5)
        row += 1
        
        # Forecast Parameters
        ttk.Label(config_frame, text="Forecast Parameters", font=('Segoe UI', 11, 'bold')).grid(
            row=row, column=0, columnspan=3, sticky=tk.W, pady=(15, 5))
        row += 1
        
        ttk.Label(config_frame, text="Forecast Months:").grid(row=row, column=0, sticky=tk.W, pady=5)
        ttk.Spinbox(config_frame, from_=1, to=36, textvariable=self.forecast_months, width=10).grid(
            row=row, column=1, sticky=tk.W, padx=(5, 0), pady=5)
        row += 1
        
        ttk.Label(config_frame, text="Confidence Level:").grid(row=row, column=0, sticky=tk.W, pady=5)
        ttk.Scale(config_frame, from_=0.8, to=0.99, variable=self.confidence_level, 
                 length=150, orient=tk.HORIZONTAL).grid(row=row, column=1, sticky=tk.W, padx=(5, 0), pady=5)
        ttk.Label(config_frame, textvariable=self.confidence_level, width=5).grid(row=row, column=2, sticky=tk.W, padx=(5, 0))
        row += 1
        
        # Output Formats
        ttk.Label(config_frame, text="Output Formats", font=('Segoe UI', 11, 'bold')).grid(
            row=row, column=0, columnspan=3, sticky=tk.W, pady=(15, 5))
        row += 1
        
        # Output Formats checkboxes (keep as ttk.Checkbutton - they work)
        for idx, (fmt, var) in enumerate(self.output_formats.items()):
            ttk.Checkbutton(config_frame, text=fmt, variable=var).grid(
                row=row, column=idx, sticky=tk.W, padx=(0, 20), pady=5)
        row += 1
        
        # Run Button - tk.Button with WHITE TEXT
        run_btn = tk.Button(
            config_frame, 
            text="Run Forecast Analysis", 
            command=self.run_forecast_analysis,
            bg='#2C3E50',        # Blue background
            fg='white',          # WHITE TEXT
            font=('Segoe UI', 10, 'bold'),
            relief='raised',
            bd=1,
            activebackground='#1A252F',
            activeforeground='white',
            cursor='hand2'       # Hand cursor on hover
        )
        run_btn.grid(row=row, column=0, columnspan=3, pady=(30, 0), sticky='ew')
        
        # Results Frame
        results_frame = ttk.LabelFrame(main_container, text="Results & Logs", padding="15")
        results_frame.grid(row=1, column=1, sticky=(tk.W, tk.E, tk.N, tk.S))
        results_frame.columnconfigure(0, weight=1)
        results_frame.rowconfigure(1, weight=1)
        
        # Progress Bar
        self.progress_var = tk.DoubleVar()
        self.progress_bar = ttk.Progressbar(results_frame, variable=self.progress_var, maximum=100)
        self.progress_bar.grid(row=0, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Status Label
        self.status_label = ttk.Label(results_frame, text="Ready to forecast")
        self.status_label.grid(row=1, column=0, sticky=tk.W, pady=(0, 5))
        
        # Results Text
        self.results_text = scrolledtext.ScrolledText(results_frame, height=20, width=50)
        self.results_text.grid(row=2, column=0, sticky=(tk.W, tk.E, tk.N, tk.S), pady=(0, 10))
        
        # Download Buttons Frame
        self.download_frame = ttk.Frame(results_frame)
        self.download_frame.grid(row=3, column=0, sticky=(tk.W, tk.E), pady=(0, 10))
        
        # Footer
        footer = ttk.Label(main_container, 
                          text=f"ForecastHub Pro v2.0 | All data processed locally | {SCRIPT_DIR}",
                          font=('Segoe UI', 8))
        footer.grid(row=2, column=0, columnspan=2, pady=(20, 0))
        
        # Make resizable
        main_container.columnconfigure(1, weight=1)
        main_container.rowconfigure(1, weight=1)
        results_frame.rowconfigure(2, weight=1)
        
        # Configure styles
        style = ttk.Style()
        style.configure('Accent.TButton', background='#3498DB', foreground='white')
        
        
    
    def browse_input_file(self):
        """Browse for input file"""
        filetypes = [
            ("CSV files", "*.csv"),
            ("Excel files", "*.xlsx;*.xls"),
            ("All files", "*.*")
        ]
        
        filename = filedialog.askopenfilename(
            title="Select sales data file",
            filetypes=filetypes,
            initialdir=SCRIPT_DIR
        )
        
        if filename:
            self.input_file.set(filename)
            self.log_message(f"Selected file: {Path(filename).name}")
    
    def browse_output_dir(self):
        """Browse for output directory"""
        directory = filedialog.askdirectory(
            title="Select output directory",
            initialdir=SCRIPT_DIR
        )
        
        if directory:
            self.output_dir.set(directory)
            self.log_message(f"Output directory: {directory}")
    
    def log_message(self, message):
        """Add message to log"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        self.results_text.insert(tk.END, f"[{timestamp}] {message}\n")
        self.results_text.see(tk.END)
        self.root.update()
    
    def update_progress(self, message, progress):
        """Update progress bar and status"""
        self.status_label.config(text=message)
        self.progress_var.set(progress)
        self.log_message(message)
        self.root.update()
    
    def run_forecast_analysis(self):
        """Run the forecast analysis in background thread"""
        # Validate input
        if not self.input_file.get():
            messagebox.showerror("Error", "Please select an input file")
            return
        
        if not Path(self.input_file.get()).exists():
            messagebox.showerror("Error", "Input file does not exist")
            return
        
        # Disable UI during processing
        for widget in self.root.winfo_children():
            try:
                widget.state(['disabled'])
            except:
                pass
        
        # Clear previous results
        self.results_text.delete(1.0, tk.END)
        for widget in self.download_frame.winfo_children():
            widget.destroy()
        
        # Run in background thread
        thread = threading.Thread(target=self._run_forecast_thread)
        thread.daemon = True
        thread.start()
    
    def _run_forecast_thread(self):
        """Background thread for forecasting"""
        try:
            self.update_progress("Initializing ForecastHub engine...", 5)
            
            # Update config with current settings
            self.config['forecast_horizon'] = self.forecast_months.get()
            self.config['confidence_level'] = self.confidence_level.get()
            
            # Validate and create output directory
            output_dir = self.output_dir.get()
            try:
                output_path = Path(output_dir).resolve()
                output_path.mkdir(parents=True, exist_ok=True)
                self.output_dir.set(str(output_path))
                self.log_message(f"âœ… Output directory set to: {output_path}")
            except Exception as e:
                self.log_message(f"âš ï¸  Could not create output directory: {e}")
                # Use default
                default_dir = SCRIPT_DIR / "forecast_reports"
                default_dir.mkdir(parents=True, exist_ok=True)
                self.output_dir.set(str(default_dir))
                self.log_message(f"âœ… Using default directory: {default_dir}")
            
            # Initialize forecaster
            forecaster = ForecastHubEngine(self.config)
            
            # Run forecast
            self.results = forecaster.run_forecast(
                self.input_file.get(),
                callback=self.update_progress
            )
            
            if not self.results['products']:
                self.update_progress("No valid forecasts generated.", 100)
                messagebox.showwarning("Warning", "No valid forecasts generated. Check your data.")
                self.enable_ui()
                return
            
            # Generate reports
            self.update_progress("Generating reports...", 85)
            
            report_gen = ForecastHubReports(self.output_dir.get())
            generated_files = []
            
            # Generate selected formats
            if self.output_formats['CSV'].get():
                csv_file = report_gen.generate_csv_report(self.results)
                generated_files.append(("CSV", csv_file))
                self.log_message(f"Generated CSV: {csv_file.name}")
            
            if self.output_formats['Excel'].get():
                excel_file = report_gen.generate_excel_report(self.results)
                generated_files.append(("Excel", excel_file))
                self.log_message(f"Generated Excel: {excel_file.name}")
            
            if self.output_formats['PDF'].get() and FPDF_AVAILABLE:
                pdf_file = report_gen.generate_pdf_report(self.results)
                generated_files.append(("PDF", pdf_file))
                self.log_message(f"Generated PDF: {pdf_file.name}")
            elif self.output_formats['PDF'].get():
                self.log_message("PDF generation skipped: fpdf not installed")
            
            # Generate charts
            if MATPLOTLIB_AVAILABLE and self.config.get("generate_charts", True):
                charts = report_gen.generate_charts(self.results)
                if charts:
                    self.log_message(f"Generated {len(charts)} charts")
            
            self.update_progress("Analysis complete!", 100)
            
            # Show summary
            summary = self.results['summary']
            summary_text = f"""
            FORECASTHUB ANALYSIS COMPLETE
            ==============================
            Products Analyzed: {summary['total_products']}
            Products Forecasted: {summary['products_forecasted']}
            High Risk Products: {summary['high_risk_products']}
            High Growth Products: {summary['high_growth_products']}
            Total Insights: {summary['total_insights']}
            
            Generated Files:
            """
            
            for fmt, file in generated_files:
                summary_text += f"  â€¢ {fmt}: {file.name}\n"
            
            self.log_message(summary_text)
            
            # Create download buttons
            self.create_download_buttons(generated_files)
            
            # Enable UI
            self.enable_ui()
            
            # Show success message
            messagebox.showinfo(
                "Success", 
                f"ForecastHub analysis complete!\n\n"
                f"Generated reports for {summary['products_forecasted']} products.\n"
                f"Files saved to: {self.output_dir.get()}"
            )
            
        except Exception as e:
            self.update_progress(f"Error: {str(e)}", 100)
            self.log_message(f"ERROR: {str(e)}")
            messagebox.showerror("Error", f"Forecast failed:\n{str(e)}")
            self.enable_ui()
    
    def create_download_buttons(self, files):
        """Create download buttons for generated files"""
        for idx, (fmt, file_path) in enumerate(files):
            btn = tk.Button(  # â† CHANGE: tk.Button instead of ttk.Button
                self.download_frame,
                text=f"Open {fmt}",
                command=lambda fp=file_path: self.open_file(fp),
                bg='#2C3E50',        # Blue background
                fg='white',          # White text
                font=('Segoe UI', 9, 'bold'),
                relief='raised',
                bd=1,
                activebackground='#1A252F',
                activeforeground='white',
                cursor='hand2'
            )
            btn.grid(row=0, column=idx, padx=(0, 10))
    
    def open_file(self, file_path):
        """Open file in default application"""
        try:
            import subprocess
            import platform
            
            if platform.system() == 'Windows':
                os.startfile(file_path)
            elif platform.system() == 'Darwin':  # macOS
                subprocess.run(['open', file_path])
            else:  # Linux
                subprocess.run(['xdg-open', file_path])
                
        except Exception as e:
            self.log_message(f"Failed to open file: {e}")
    
    def enable_ui(self):
        """Enable UI controls"""
        for widget in self.root.winfo_children():
            try:
                widget.state(['!disabled'])
            except:
                pass
        self.root.update()
    
    def run(self):
        """Run the application"""
        self.root.mainloop()

# ============================================
# CONSOLE INTERFACE (FALLBACK)
# ============================================
def run_console_mode():
    """Run ForecastHub in console mode"""
    print("\n" + "="*60)
    print("FORECASTHUB PRO - Console Mode")
    print("="*60)
    print("\nFeatures:")
    print("  â€¢ Advanced statistical forecasting")
    print("  â€¢ Multiple output formats (CSV, Excel, PDF)")
    print("  â€¢ Risk assessment & business insights")
    print("  â€¢ 100% local processing - No data leaves your computer")
    print("\n" + "="*60)
    
    # Check dependencies
    if not STATSMODELS_AVAILABLE:
        print("\nâš ï¸  WARNING: statsmodels not installed.")
        print("   Advanced forecasting features will be limited.")
        print("   Install with: pip install statsmodels")
    
    # Get input file
    input_file = input("\nEnter sales data file path (or drag & drop file): ").strip('"')
    
    if not input_file:
        # Try default files
        default_files = ['sales.csv', 'sales_data.csv', 'data.csv', 'sales.xlsx']
        for default in default_files:
            if (SCRIPT_DIR / default).exists():
                input_file = str(SCRIPT_DIR / default)
                print(f"Using default file: {default}")
                break
        
        if not input_file:
            print("âŒ No file specified.")
            return
    
    if not Path(input_file).exists():
        print(f"âŒ File not found: {input_file}")
        return
    
    # Get forecast months
    try:
        forecast_months = int(input("Forecast months (default 12): ") or "12")
    except:
        forecast_months = 12
    
    # Get output directory
    output_dir = input(f"Output directory (default: {SCRIPT_DIR / 'forecast_reports'}): ")
    if not output_dir:
        output_dir = SCRIPT_DIR / "forecast_reports"
    
    # Get output formats
    print("\nSelect output formats (comma-separated):")
    print("1. CSV")
    print("2. Excel")
    print("3. PDF")
    format_choice = input("Choices (default: 1,2,3): ") or "1,2,3"
    
    formats = []
    if '1' in format_choice:
        formats.append('CSV')
    if '2' in format_choice:
        formats.append('Excel')
    if '3' in format_choice:
        formats.append('PDF')
    
    # Run forecast
    print("\nðŸš€ Starting forecast analysis...")
    
    try:
        # Update config
        config = load_config()
        config['forecast_horizon'] = forecast_months
        config['default_output_dir'] = str(output_dir)
        
        # Initialize forecaster
        forecaster = ForecastHubEngine(config)
        
        # Run forecast with progress callback
        def console_progress(message, progress):
            print(f"[{progress:.0f}%] {message}")
        
        results = forecaster.run_forecast(input_file, callback=console_progress)
        
        if not results['products']:
            print("âŒ No valid forecasts generated.")
            return
        
        # Generate reports
        print("\nðŸ“Š Generating reports...")
        report_gen = ForecastHubReports(output_dir)
        generated_files = []
        
        if 'CSV' in formats:
            csv_file = report_gen.generate_csv_report(results)
            generated_files.append(("CSV", csv_file))
            print(f"âœ… Generated CSV: {csv_file.name}")
        
        if 'Excel' in formats:
            excel_file = report_gen.generate_excel_report(results)
            generated_files.append(("Excel", excel_file))
            print(f"âœ… Generated Excel: {excel_file.name}")
        
        if 'PDF' in formats and FPDF_AVAILABLE:
            pdf_file = report_gen.generate_pdf_report(results)
            generated_files.append(("PDF", pdf_file))
            print(f"âœ… Generated PDF: {pdf_file.name}")
        elif 'PDF' in formats:
            print("âš ï¸ PDF generation skipped: fpdf not installed")
        
        # Generate charts
        if MATPLOTLIB_AVAILABLE:
            charts = report_gen.generate_charts(results)
            if charts:
                print(f"âœ… Generated {len(charts)} charts")
        
        # Show summary
        summary = results['summary']
        print("\n" + "="*60)
        print("FORECASTHUB ANALYSIS COMPLETE")
        print("="*60)
        print(f"\nSummary:")
        print(f"  â€¢ Products Analyzed: {summary['total_products']}")
        print(f"  â€¢ Products Forecasted: {summary['products_forecasted']}")
        print(f"  â€¢ High Growth Products: {summary['high_growth_products']}")
        print(f"  â€¢ Total Insights: {summary['total_insights']}")
        print(f"\nFiles saved to: {output_dir}")
        
        # Open output directory
        open_dir = input("\nOpen output directory? (y/n): ").lower()
        if open_dir == 'y':
            import subprocess
            import platform
            
            if platform.system() == 'Windows':
                os.startfile(output_dir)
            elif platform.system() == 'Darwin':
                subprocess.run(['open', output_dir])
            else:
                subprocess.run(['xdg-open', output_dir])
        
    except Exception as e:
        print(f"\nâŒ Error: {str(e)}")
        print(traceback.format_exc())

# ============================================
# MAIN ENTRY POINT
# ============================================
if __name__ == "__main__":
    # Check command line arguments
    if len(sys.argv) > 1 and sys.argv[1] == "--console":
        run_console_mode()
    else:
        # Check if GUI is available
        try:
            # Run GUI application
            app = ForecastHubApp()
            print(f"ðŸš€ Starting ForecastHub Pro from: {SCRIPT_DIR}")
            print(f"ðŸ“ Working directory: {os.getcwd()}")
            app.run()
        except Exception as e:
            print(f"GUI failed: {e}")
            print("Falling back to console mode...")
            run_console_mode()